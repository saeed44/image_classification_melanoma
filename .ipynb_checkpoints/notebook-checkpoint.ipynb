{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import efficientnet.tfkeras as efn\n",
    "from kaggle_datasets import KaggleDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "\n",
    "# tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Data access\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('melanoma-512x512')\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 13\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "IMAGE_SIZE = [512, 512]        #[299, 299]\n",
    "\n",
    "\n",
    "FILENAMES =  tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')\n",
    "TEST_FILENAMES = tf.io.gfile.glob(KaggleDatasets().get_gcs_path('melanoma-512x512') + '/test*.tfrec')\n",
    "FILENAMES_df = pd.DataFrame({\"FILENAMES\":FILENAMES})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    # convert image to floats in [0, 1] range\n",
    "    image = tf.cast(image, tf.float32) / 255.0 \n",
    "    # explicit size needed for TPU\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"patient_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"age_approx\": tf.io.FixedLenFeature([], tf.int64),  \n",
    "        \"sex\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"anatom_site_general_challenge\": tf.io.FixedLenFeature([],tf.int64),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    \n",
    "    #image data\n",
    "    image = decode_image(example['image'])\n",
    "    \n",
    "    # tabular data\n",
    "    data = {}\n",
    "    data['patient_id'] = tf.cast(example['patient_id'], tf.float32) \n",
    "    data['age'] = tf.cast(example['age_approx'], tf.float32)/30.\n",
    "    data['sex'] = tf.cast(example['sex'], tf.float32)\n",
    "    data['anatom_site'] = tf.cast(example['anatom_site_general_challenge'], tf.float32)\n",
    "    # label\n",
    "    label = tf.cast(example['target'], tf.int32)\n",
    "    return image, label, data \n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"patient_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"age_approx\": tf.io.FixedLenFeature([], tf.int64),  \n",
    "        \"sex\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"anatom_site_general_challenge\": tf.io.FixedLenFeature([],tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    \n",
    "    #image data\n",
    "    image = decode_image(example['image'])\n",
    "    \n",
    "    # tabular data\n",
    "    data = {}\n",
    "    data['patient_id'] = tf.cast(example['patient_id'], tf.float32)\n",
    "    data['image_name'] = tf.cast(example['image_name'], tf.string)\n",
    "    data['age'] = tf.cast(example['age_approx'], tf.float32)/30.\n",
    "    data['sex'] = tf.cast(example['sex'], tf.float32)\n",
    "    data['anatom_site'] = tf.cast(example['anatom_site_general_challenge'], tf.float32)\n",
    "    # label\n",
    "    \n",
    "    return image, data # returns a dataset of (image, label) pairs\n",
    "\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. \n",
    "    \n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        # disable order, increase speed\n",
    "        ignore_order.experimental_deterministic = False\n",
    "\n",
    "    # automatically interleaves reads from multiple files\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
    "    # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True \n",
    "    # or (image, id) pairs if labeled=False\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled \n",
    "                          else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_features = [\"age\", \"sex\", \"anatom_site\"]\n",
    "Num_features = len(tab_features)\n",
    "\n",
    "def setup_input(image, label, data):\n",
    "    \n",
    "    tab_data=[tf.cast(data[tfeat], dtype=tf.float32) for tfeat in tab_features]\n",
    "    \n",
    "    tabular=tf.stack(tab_data)\n",
    "    \n",
    "    return {'inp1': image, 'inp2':  tabular}, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(data, label):\n",
    "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n",
    "    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n",
    "    # of the TPU while the TPU itself is computing gradients.\n",
    "    image = tf.image.random_flip_left_right(data['inp1'])\n",
    "#     image = tf.image.random_brightness(image, 0.1)\n",
    "#     image = tf.image.adjust_contrast(image, 2)\n",
    "#     image = tf.image.random_hue(image, 0.2)\n",
    "#     image = tf.image.random_saturation(image, lower, upper, seed=None)\n",
    "#     image = tf.image.central_crop(image, central_fraction=0.5)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    \n",
    "    return {'inp1': image, 'inp2': data['inp2']} ,label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataset(TRAIN_FILENAMES):\n",
    "    dataset = load_dataset(TRAIN_FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(setup_input, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(VALIDATION_FILENAMES, ordered=False):\n",
    "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n",
    "    dataset = dataset.map(setup_input, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(dataset, ordered=False):\n",
    "#     dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "#     dataset = dataset.map(setup_input, num_parallel_calls=AUTO)\n",
    "#     dataset = dataset.map(data_augment, num_parallel_calls=AUTO)   #use when train is augmented\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAINING_IMAGES = count_data_items(FILENAMES)#*(folds-1)/folds\n",
    "# NUM_VALIDATION_IMAGES = count_data_items(FILENAMES)/folds\n",
    "\n",
    "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## model with metadata and image  #############\n",
    "\n",
    "def get_model(model, IMAGE_SIZE, Num_features):\n",
    "    \n",
    "    # chose a model=[EfficientNetB5, InceptionV3, ResNet50, ResNet50V2, NASNetLarge]\n",
    "    with strategy.scope():\n",
    "        if model == \"EfficientNetB5\":\n",
    "            pretrained_model = efn.EfficientNetB5(\n",
    "                    input_shape = (*IMAGE_SIZE, 3),\n",
    "                    weights = 'imagenet',\n",
    "                    include_top = False)\n",
    "\n",
    "        elif model == \"InceptionV3\":\n",
    "            pretrained_model = tf.keras.applications.InceptionV3(\n",
    "                    input_shape = (*IMAGE_SIZE, 3),\n",
    "                    weights = 'imagenet',\n",
    "                    include_top = False)\n",
    "            \n",
    "        elif model == \"ResNet50\":\n",
    "            pretrained_model = tf.keras.applications.ResNet50(\n",
    "                    input_shape=(*IMAGE_SIZE,3),\n",
    "                    weights='imagenet',\n",
    "                    include_top=False)\n",
    "        elif model == \"ResNet50V2\":\n",
    "            pretrained_model = tf.keras.applications.ResNet50V2(\n",
    "                    input_shape=(*IMAGE_SIZE,3),\n",
    "                    weights='imagenet',\n",
    "                    include_top=False)\n",
    "        elif model == \"NASNetLarge\" :\n",
    "            pretrained_model = tf.keras.applications.NASNetLarge(\n",
    "                    include_top=False,\n",
    "                    input_shape=(*IMAGE_SIZE,3),\n",
    "                    weights='imagenet' )\n",
    "        elif model == \"MobileNetV2\":\n",
    "            pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "                    input_shape=(*IMAGE_SIZE,3), weights='imagenet',include_top=False,alpha=1.0)\n",
    "        elif model == \"DenseNet201\":\n",
    "            pretrained_model = tf.keras.applications.DenseNet201(\n",
    "                    input_shape=(*IMAGE_SIZE,3), include_top=False, weights='imagenet' )\n",
    "            \n",
    "            \n",
    "            \n",
    "        pretrained_model.trainable = True\n",
    "\n",
    "        inp1 = tf.keras.layers.Input(shape=(*IMAGE_SIZE, 3), name='inp1')\n",
    "        inp2 = tf.keras.layers.Input(shape=(Num_features), name='inp2')\n",
    "\n",
    "        # might consider kernel regualizer in the dense leyers\n",
    "        x = pretrained_model(inp1)\n",
    "        x = L.GlobalAveragePooling2D()(x)\n",
    "        x = L.Dense(1024, activation = 'relu')(x) \n",
    "        x = L.Dropout(0.3)(x)\n",
    "        x = L.Dense(512, activation= 'relu')(x) \n",
    "        x = L.Dropout(0.2)(x)\n",
    "        x = L.Dense(256, activation='relu')(x)\n",
    "        x = L.Dropout(0.2)(x)\n",
    "        x = L.Dense(128, activation='relu')(x)\n",
    "        x = L.Dropout(0.1)(x)\n",
    "        # add a layer for the tabular features\n",
    "        y = L.Dense(64, activation='relu')(inp2)\n",
    "\n",
    "        # concatinate the two nets\n",
    "        concat = L.concatenate([x,y])\n",
    "\n",
    "        output = L.Dense(1, activation='sigmoid', name='output')(concat)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs =[inp1,inp2], outputs=[output])\n",
    "        \n",
    "    model.compile( optimizer='adam',\n",
    "    #loss = 'binary_crossentropy',\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.2),\n",
    "    metrics= ['AUC']       #['binary_crossentropy']\n",
    "              )\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataset(dataset, ordered=False):\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def setup_test_name(image, data):\n",
    "    return data['image_name']\n",
    "\n",
    "def setup_test_image(image, data):    \n",
    "    \n",
    "    tab_data=[tf.cast(data[tfeat], dtype=tf.float32) for tfeat in [\"age\", \"sex\", \"anatom_site\"]]\n",
    "    tabular=tf.stack(tab_data)\n",
    "    return {'inp1': image, 'inp2': tabular}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold  \n",
    "\n",
    "early_stopping = EarlyStopping( monitor='val_auc', verbose=1, patience=4,\n",
    "                                mode='max', restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "def trained_models(folds = 6, EPOCHS = 8):\n",
    "    \n",
    "    kfold = KFold(folds, shuffle = True, random_state = 1002)\n",
    "\n",
    "#     history=[]\n",
    "    models=[]\n",
    "    histories=[]\n",
    "\n",
    "    for fold, (trn_index, val_index) in enumerate(kfold.split(FILENAMES)):\n",
    "            print(f\"Fold {fold+1}\")\n",
    "            \n",
    "            TRAIN_FILENAMES = list(FILENAMES_df.loc[trn_index]['FILENAMES'])\n",
    "            NUM_TRAINING_IMAGES = count_data_items(TRAIN_FILENAMES)\n",
    "            VALIDATION_FILENAMES = list(FILENAMES_df.loc[val_index]['FILENAMES'])\n",
    "        \n",
    "            checkpoint_name = f'model_fold_{fold+1}' + '.h5'\n",
    "        \n",
    "            model_checkpoint = ModelCheckpoint(checkpoint_name \n",
    "                           ,monitor='val_auc', mode='max', verbose=1, save_best_only=True, \n",
    "                            save_weights_only=True, save_freq='epoch')\n",
    "            \n",
    "            model = get_model(\"EfficientNetB5\",IMAGE_SIZE, Num_features)  \n",
    "            \n",
    "            history = model.fit_generator(\n",
    "                   get_training_dataset(TRAIN_FILENAMES),\n",
    "                   steps_per_epoch = NUM_TRAINING_IMAGES // BATCH_SIZE,\n",
    "                   epochs = EPOCHS,\n",
    "#                   verbose = 1,\n",
    "                   validation_data = get_validation_dataset(VALIDATION_FILENAMES),\n",
    "                   callbacks = [early_stopping, lr_ramp_up, model_checkpoint]\n",
    "#                   validation_steps = int(950 // batch_size)\n",
    "                   ,class_weight={0: 1, 1: 20}\n",
    "                    )\n",
    "        \n",
    "#             print('Load best weights for model prediction')\n",
    "#             model.load_weights(checkpoint_name)\n",
    "            models.append(model)\n",
    "            histories.append(history)\n",
    "            \n",
    "    return models, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, histories = trained_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(models):\n",
    "\n",
    "    preds = pd.DataFrame({'image_name': np.zeros(NUM_TEST_IMAGES)})\n",
    "\n",
    "\n",
    "    test_ds = load_dataset(TEST_FILENAMES, labeled=False, ordered=True)\n",
    "    test_images_ds = test_ds.map(setup_test_image, num_parallel_calls=AUTO)\n",
    "    test_images_ds = get_test_dataset(test_images_ds)\n",
    "\n",
    "\n",
    "    test_ds = get_test_dataset(test_ds)\n",
    "    test_ids_ds = test_ds.map(setup_test_name, num_parallel_calls=AUTO).unbatch()\n",
    "\n",
    "\n",
    "    preds['image_name'] = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i,model in enumerate(models):\n",
    "        \n",
    "        preds['target'+str(i+1)] = model.predict(test_images_ds)\n",
    "        print(\"*\"*50,'\\n', str(i+1)+'th prediction done!','\\n')\n",
    "    \n",
    "    preds['target'] = preds.mean(axis=1)\n",
    "    \n",
    "    return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = make_preds(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
